{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a SQL database for PurpleAir \n",
    "\n",
    "#### Author: Yunha Lee, Ph.D. \n",
    "#### Date  : Dec 01, 2022\n",
    "\n",
    "The code below is designed to create a database using SQLite in your local computer. It takes real-time data from a purple air sensor and stores in the database.  PurpleAir limits public access to their historical database, so this allows to build your own sensor database. \n",
    "\n",
    "* The current version uses the \"purpleair\" library from GitHub, which handles Purple Air API: https://github.com/csm10495/purpleair\n",
    "* SQLite is chosen for this because "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Side Note about PurpleAir database\n",
    "\n",
    "PurpleAir has recently changed the database access methods.  \n",
    "\n",
    "As of December, 2022, the recommended methods to get PurpleAir data are the below:\n",
    "\n",
    "1) using their \"Sensor data download tool\" website (without API)\n",
    "    see link: https://www.purpleair.com/sensorlist\n",
    "2) using real-time API to create your own \"personal\" database, instead of using their historical API\n",
    "    see link: https://community.purpleair.com/t/historical-api-endpoints-are-now-restricted/1557\n",
    "3) using the historical API occasionally to get the missed data\n",
    "    email contact@purpleair.com to get a permission to use the history API. \n",
    "\n",
    "\n",
    "*The jupyter notebook is designed to support the method \"2\", building your own database in a local computer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from purpleair import PurpleAir\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "from io import StringIO\n",
    "import sqlalchemy as db\n",
    "import schedule\n",
    "\n",
    "def flatten_json(data: dict) -> dict:\n",
    "  \n",
    "    flat_data = dict()\n",
    "    for key, value in data.items():\n",
    "        if not isinstance(value, dict):\n",
    "            flat_data[key] = value\n",
    "        else:\n",
    "\n",
    "            # 1st nested item\n",
    "            for k, v in value.items():\n",
    "                if (k == \"stats_a\"):\n",
    "                    print(\"not saving stats_a information \", k)\n",
    "                else:\n",
    "\n",
    "                    if not isinstance(v, dict):\n",
    "                        flat_data[key + \"_\" + k] = v\n",
    "                    else:\n",
    "\n",
    "                        # 2nd nested items\n",
    "                        for k2, v2 in v.items():\n",
    "                            if not isinstance(v2, dict):\n",
    "                                flat_data[key + \"_\"+ k+ \"_\"+ k2] = v2\n",
    "                            else: \n",
    "\n",
    "                                # 3rd nested items\n",
    "                                for k3, v3 in v.items():\n",
    "                                    if not isinstance(v3, dict):\n",
    "                                        flat_data[key + \"_\"+ k+ \"_\"+ k2+ \"_\"+ k3] = v3\n",
    "                                    else:\n",
    "                                        print(\"WARNING: this json file has more than 3rd nested layers\")\n",
    "      \n",
    "    return flat_data\n",
    "\n",
    "def get_PA_data(key_read, sensor_id):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    key_read : your PurpleAir API key \n",
    "    sensor_id : ID number of the sensor you want to read\n",
    "    \"\"\"\n",
    "\n",
    "    # get real-time sensor data \n",
    "    p = PurpleAir(key_read)\n",
    "    json_data = p.get_sensor_data(sensor_id)\n",
    "\n",
    "    # Flatten multi-nested json data to a dictionary\n",
    "    flat_data = flatten_json(data= json_data)\n",
    "\n",
    "    # Create a pandas dataframe \n",
    "    df = pd.DataFrame(flat_data, index=[0])\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_sql_csv (save_as_sql=True, save_as_csv=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    key_read : your PurpleAir API key \n",
    "    sensor_id : ID number of the sensor you want to read\n",
    "    db_path : database directory path\n",
    "    engine : SQL engine info\n",
    "    save_as_sql : Boolean value to save the data as SQLite \n",
    "    save_as_csv : Boolean value to save the data as CSV\n",
    "    \"\"\"\n",
    "\n",
    "    df = get_PA_data(key_read, sensor_id)\n",
    "\n",
    "    # Writing to SQLite Table (Optional)\n",
    "    sql_tablename = 'purpleair_' + sensor_id\n",
    "    df.to_sql(sql_tablename, con=engine, if_exists='replace', index=True)\n",
    "\n",
    "    # writing to csv file\n",
    "    csv_filename = db_path + '/sensor_index_' + sensor_id + '.csv'\n",
    "    df.to_csv(csv_filename, index=False, header=True)\n",
    "\n",
    "    return\n",
    "\n",
    "def append_sql_csv (save_as_sql=True, save_as_csv=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    key_read : your PurpleAir API key \n",
    "    sensor_id : ID number of the sensor you want to read\n",
    "    db_path : database directory path\n",
    "    engine : SQL engine info\n",
    "    save_as_sql : Boolean value to save the data as SQLite \n",
    "    save_as_csv : Boolean value to save the data as CSV\n",
    "    \"\"\"\n",
    "\n",
    "    df = get_PA_data(key_read, sensor_id)\n",
    "    print(df)\n",
    "\n",
    "    # Writing to SQLite Table (Optional)\n",
    "    sql_tablename = 'purpleair_' + sensor_id\n",
    "    df.to_sql(sql_tablename, con=engine, if_exists='append', index=False)\n",
    "\n",
    "    # writing to csv file\n",
    "    csv_filename = db_path + '/sensor_index_' + sensor_id + '.csv'\n",
    "    df.to_csv(csv_filename, index=False, header=False, mode='a')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2324129-7000-11ED-B6F4-42010A800007 36\n",
      "database dir is created :  ./database_Mar-16-2023-16_45_50\n",
      "os.path.abspath(sql_path): /Users/yunhalee/Desktop/DLair/purpleair_indoor_aqi/database_Mar-16-2023-16_45_50/purpleair_143856.sqlite\n",
      "not saving stats_a information  stats_a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Every 2 minutes do append_sql_csv(save_as_sql=True, save_as_csv=True) (last run: [never], next run: 2023-03-16 16:47:50)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a sensor index \n",
    "sensor_id = '143856'\n",
    "\n",
    "# minutes time frequency of generating PA real-time data\n",
    "pa_time = 2 # according to PA, every 2 minutes\n",
    "\n",
    "# API Keys provided by PurpleAir(c)\n",
    "key_dir = \"./purpleair_api_read_key\"\n",
    "with open(key_dir) as f:\n",
    "    key_read = f.readlines()[0]\n",
    "    key_read = key_read.strip() # could contain whitespace\n",
    "    print(key_read, len(key_read))\n",
    "\n",
    "\n",
    "# create database directory\n",
    "db_path = \"./database_\" + datetime.now().strftime(\"%b-%d-%Y-%H_%M_%S\")\n",
    "#db_path = \"./database\"  # _\" + datetime.now().strftime(\"%d-%m-%Y-%H_%M_%S\")\n",
    "\n",
    "\n",
    "print(\"database dir is created : \", db_path)\n",
    "if not os.path.exists(db_path):\n",
    "    os.makedirs(db_path)\n",
    "\n",
    "# Starting engine for SQLite\n",
    "sql_path = db_path + \"/purpleair_\"+ sensor_id +\".sqlite\"\n",
    "print(f'os.path.abspath(sql_path): {str(os.path.abspath(sql_path))}')\n",
    "SQL_URI = \"sqlite:///\" + os.path.abspath(sql_path) \n",
    "engine = db.create_engine(SQL_URI)\n",
    "\n",
    "# create sql and/or csv files\n",
    "create_sql_csv(save_as_sql=True, save_as_csv=True)\n",
    "\n",
    "# calling append_sql_csv every two minutes to create historical database from real-time data\n",
    "schedule.every(pa_time).minutes.do(append_sql_csv, save_as_sql=True, save_as_csv=True)\n",
    "\n",
    "#while True:\n",
    "#    schedule.run_pending()\n",
    "#    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'V1.0.11-0.0.42', 1678999550, 1678999526, 143856, 1657586037, 1643666340, 1678999510, 0, 0, 'Bren Mar Park', 0, 1, 'PA-I', '2.0+BME280+PMSX003-A', 35, '7.02', -55, 2648, 191, 16192, 5, 38.797955, -77.15579, 198, 1, 0, 0, 0, 30, 12, 12, 79, 79, 1010.13, 1010.13, 0.02, 0.0, 0.0, 0.0, 0.0, 0.6, 0.6, 0.0, 0.0, 2.0, 2.0, 2.2, 2.2, 313.3, 313.3, 136, 136, 37, 37, 5, 5, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1644241, 'SKCQN9XL3HRMIO03', 1644243, 'WBOFV6KCLBHSDLEK', 1644242, 'IZB5PHB5U8VGOUI2', 1644244, '7LNT1JWRO1DH2ME1', 0.0, 0.1, 0.4, 0.6, 0.5, 1.2, 2.9, 1678999510)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read all sql database for testing  \n",
    "test = pd.read_sql('purpleair_'+sensor_id, engine)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      api_version  time_stamp  data_time_stamp  sensor_sensor_index  \\\n",
      "0  V1.0.11-0.0.42  1678999550       1678999526               143856   \n",
      "\n",
      "   sensor_last_modified  sensor_date_created  sensor_last_seen  \\\n",
      "0            1657586037           1643666340        1678999510   \n",
      "\n",
      "   sensor_private  sensor_is_owner    sensor_name  ...  sensor_secondary_id_b  \\\n",
      "0               0                0  Bren Mar Park  ...                1644244   \n",
      "\n",
      "   sensor_secondary_key_b sensor_stats_pm2.5 sensor_stats_pm2.5_10minute  \\\n",
      "0        7LNT1JWRO1DH2ME1                0.0                         0.1   \n",
      "\n",
      "   sensor_stats_pm2.5_30minute  sensor_stats_pm2.5_60minute  \\\n",
      "0                          0.4                          0.6   \n",
      "\n",
      "   sensor_stats_pm2.5_6hour  sensor_stats_pm2.5_24hour  \\\n",
      "0                       0.5                        1.2   \n",
      "\n",
      "   sensor_stats_pm2.5_1week  sensor_stats_time_stamp  \n",
      "0                       2.9               1678999510  \n",
      "\n",
      "[1 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "# read CSV files\n",
    "csv_filename = db_path + '/sensor_index_' + sensor_id + '.csv'\n",
    "df = pd.read_csv(csv_filename)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the database directory \n",
    "\n",
    "for f in os.listdir(db_path):\n",
    "    os.remove(os.path.join(db_path, f))\n",
    "\n",
    "os.rmdir(db_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('MLbase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9a029205006443da9f74c396dcb2cd2cedf354383a57d959fc5041332eef244"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
